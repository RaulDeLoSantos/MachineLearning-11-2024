{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JWt2bpPwwETxB_kz0AZ0HTY_oFtNtvNW",
      "authorship_tag": "ABX9TyNPx7Fm1Fhj/Hb0L9stSTGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaulDeLoSantos/MachineLearning-11-2024/blob/development/I_ModeloAprendSupervl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Ejemplo de Aprendizaje Supervisado: Predicción de Especies de Flores Iris\n",
        "Este ejemplo muestra cómo entrenar un modelo para predecir la especie de una flor de iris basándose en las medidas de sus sépalos y pétalos.\n",
        "\n",
        "1. Recopilar y preparar un conjunto de datos etiquetados.\n",
        "\n",
        "Utilizaremos el popular conjunto de datos Iris, que está integrado en scikit-learn:\n",
        "\n"
      ],
      "metadata": {
        "id": "AcIr2-pKM2-N"
      }
    },
    {
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data  # Características (longitud del sépal, ancho del sépal, longitud del pétal, ancho del pétal)\n",
        "y = iris.target  # Etiquetas (especies: 0, 1, o 2)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "uIfRNo8RMUab"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## agregar visualizacion o impresion\n",
        "print (iris.feature_names)\n",
        "print (iris.target_names )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5i-VCF6MomZ",
        "outputId": "7259afc2-1411-4438-d7ba-7b8d7dd44288"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "Utilizaremos el 80% de los datos para el entrenamiento y el 20% para las pruebas:"
      ],
      "metadata": {
        "id": "aTm-v43ANcrC"
      }
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\"\"\"  #  propuesto por Colab notebook\n",
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\"\"\"\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SycM-hbOrSS",
        "outputId": "ad27ff6e-c2a6-4b09-8257-ce88754273b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120,)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Entrenar el modelo utilizando el conjunto de entrenamiento.\n",
        "Utilizaremos un modelo de regresión logística simple:"
      ],
      "metadata": {
        "id": "RbySsLKYPuCi"
      }
    },
    {
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo = LogisticRegression(max_iter=1000)  # 1000 =  Preciion 1 - Aumentar max_iter si es necesario\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Datos Originales\")\n",
        "## agregar visualizacion o impresion\n",
        "print (iris.feature_names)\n",
        "print (iris.target_names )\n",
        "\"\"\"\n",
        "print (iris.shape())\n",
        "print (iris.head())\n",
        "print (iris.describe())\n",
        "print (iris.groupby('species').size())\n",
        "\"\"\"\n",
        "print (\"Entrenamiento completado.\")\n",
        "print (\"Precisión del modelo:\", modelo.score(X_test, y_test))\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJZ0IzexQQSs",
        "outputId": "1da7a123-64b1-485e-8b95-1243764fa022"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos Originales\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "Entrenamiento completado.\n",
            "Precisión del modelo: 1.0\n",
            "(120, 4)\n",
            "(30, 4)\n",
            "(120,)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluar el rendimiento del modelo utilizando el conjunto de prueba.\n",
        "\n",
        "Utilizaremos la precisión como nuestra métrica de evaluación:"
      ],
      "metadata": {
        "id": "7BfvHm7dhoZI"
      }
    },
    {
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = modelo.predict(X_test)\n",
        "precision = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión: {precision}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKnbHLophvgY",
        "outputId": "de0c7277-e2e9-4003-f728-31fb3fd6a6d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Ajustar los hiperparámetros del modelo y repetir los pasos 3-4 hasta lograr el rendimiento deseado.\n",
        "\n",
        "Podríamos probar diferentes valores para el parámetro max_iter de LogisticRegression o utilizar un modelo completamente diferente. Este paso es iterativo e implica experimentar para encontrar la mejor configuración."
      ],
      "metadata": {
        "id": "TAI8G6X8h0ii"
      }
    },
    {
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carga el dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define los hiperparámetros que deseas ajustar y sus posibles valores\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
        "    'penalty': ['l1', 'l2'],  # Tipo de regularización\n",
        "    'solver': ['liblinear', 'saga']  # Algoritmo de optimización\n",
        "}\n",
        "\n",
        "# Crea un objeto GridSearchCV para buscar la mejor combinación de hiperparámetros\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Ajusta el modelo utilizando GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtén el mejor modelo y sus hiperparámetros\n",
        "mejor_modelo = grid_search.best_estimator_\n",
        "mejores_hiperparametros = grid_search.best_params_\n",
        "\n",
        "# Evalúa el mejor modelo en el conjunto de prueba\n",
        "y_pred = mejor_modelo.predict(X_test)\n",
        "precision = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del mejor modelo: {precision}\")\n",
        "print(f\"Mejores hiperparámetros: {mejores_hiperparametros}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zugjUb3juw8",
        "outputId": "57a42fdf-7ac3-4d0b-a7f1-4e37425a3f8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del mejor modelo: 1.0\n",
            "Mejores hiperparámetros: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justificación:\n",
        "\n",
        "Dataset load_iris: El código carga el dataset iris utilizando load_iris() de sklearn.datasets, el cual ya contiene las características (X) y las etiquetas (y).\n",
        "param_grid: Se han añadido más opciones de hiperparámetros específicos para LogisticRegression al trabajar con el dataset iris:\n",
        "'solver': Se incluyen dos algoritmos de optimización, 'liblinear' y 'saga', que son adecuados para este tipo de datos. Puedes experimentar con otros solvers como 'lbfgs', 'newton-cg' si lo deseas.\n",
        "GridSearchCV, fit, best_estimator_, best_params_, accuracy_score: El resto del código funciona igual que en el ejemplo anterior, buscando la mejor combinación de hiperparámetros, entrenando el modelo, obteniendo el mejor modelo y evaluando su precisión.\n",
        "Al ejecutar este código, se buscarán la mejor combinación de C, penalty y solver para el modelo LogisticRegression utilizando el dataset iris, imprimiendo la precisión del mejor modelo y los hiperparámetros que la lograron.\n",
        "\n",
        "Recuerda que puedes modificar los valores en param_grid para explorar otras posibilidades y ajustar el modelo de manera más precisa. También, puedes considerar otros modelos, como Support Vector Machines (SVM) o K-Nearest Neighbors (KNN) y ajustar sus hiperparámetros de forma similar.\n"
      ],
      "metadata": {
        "id": "47L5kwU6j_Iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Usar el modelo entrenado para hacer predicciones sobre nuevos datos."
      ],
      "metadata": {
        "id": "_rzo74iAiDrA"
      }
    },
    {
      "source": [
        "nuevos_datos = [[5.1, 3.5, 1.4, 0.2]]  # Ejemplo de nuevo punto de datos\n",
        "prediccion = modelo.predict(nuevos_datos)\n",
        "print(f\"Predicción: {prediccion}\")  # Salida: Especie predicha"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbyOaTHMiPjp",
        "outputId": "19581b9f-03d2-4645-e7df-c8fb14851b4f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicción: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Aprendizaje no supervisado:\n",
        "\n",
        "Este ejemplo se centra en el aprendizaje supervisado. El aprendizaje no supervisado implicaría el uso de algoritmos como la agrupación en clústeres (por ejemplo, KMeans) para agrupar las flores de iris en función de sus características sin utilizar las etiquetas de las especies.\n",
        "\n",
        "Espero que esto te ayude a comprender mejor el proceso de aprendizaje supervisado en Python con el conjunto de datos Iris. No dudes en preguntarme si tienes alguna duda o si quieres explorar otros aspectos."
      ],
      "metadata": {
        "id": "vZrbItXKic1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conslusiones\n",
        "\n",
        "Inferencias del dataset Iris y los algoritmos:\n",
        "\n",
        "Separabilidad de Clases: El dataset Iris es relativamente sencillo, con tres clases de flores (Setosa, Versicolor, Virginica) que son en su mayoría linealmente separables. Esto significa que algoritmos simples como la Regresión Logística o el SVM lineal pueden lograr un buen rendimiento.\n",
        "\n",
        "Importancia de las Características: Algunas características, como la longitud y el ancho del pétalo, son más importantes para la clasificación que otras. Esto se puede observar al analizar la importancia de las características de los modelos o visualizando los datos.\n",
        "\n",
        "Complejidad del Modelo: Para este dataset, modelos simples suelen ser suficientes. Modelos más complejos, como redes neuronales profundas, podrían ser propensos al sobreajuste y no proporcionar una mejora significativa en el rendimiento.\n",
        "\n",
        "Cómo mejorar el modelo:\n",
        "\n",
        "Ingeniería de Características: Aunque el dataset Iris ya tiene características bien definidas, se podría experimentar con la creación de nuevas características, como la relación entre la longitud y el ancho del pétalo, para ver si mejora el rendimiento.\n",
        "\n",
        "Selección de Modelo: Probar diferentes algoritmos de clasificación, como KNN, Árboles de Decisión o Random Forest, y comparar su rendimiento. Elegir el modelo que mejor se adapte a los datos y al problema específico.\n",
        "\n",
        "Ajuste de Hiperparámetros: Optimizar los hiperparámetros del modelo seleccionado utilizando técnicas como Grid Search o Random Search para encontrar la mejor configuración.\n",
        "\n",
        "Validación Cruzada: Utilizar técnicas de validación cruzada, como k-fold, para obtener una estimación más robusta del rendimiento del modelo y evitar el sobreajuste.\n",
        "\n",
        "Aumento de Datos: Si se dispone de pocos datos, se podría considerar el aumento de datos para generar nuevas muestras y mejorar la generalización del modelo.\n",
        "\n",
        "Análisis de Errores: Analizar los errores del modelo para identificar patrones y áreas de mejora. Esto podría implicar revisar los datos de entrenamiento, ajustar el modelo o considerar un enfoque diferente.\n",
        "\n",
        "En resumen:\n",
        "\n",
        "El dataset Iris es un buen punto de partida para aprender sobre el aprendizaje automático y la clasificación. Se pueden aplicar diversos algoritmos para lograr un buen rendimiento, y la mejora del modelo se puede lograr a través de la ingeniería de características, la selección de modelos, el ajuste de hiperparámetros, la validación cruzada y el análisis de errores.\n",
        "\n",
        "Recuerda que no hay un enfoque único para todos los casos, y la mejor manera de mejorar un modelo es experimentar y analizar los resultados.\n",
        "\n",
        "Espero que esto te ayude a comprender mejor cómo inferir información del dataset Iris y los algoritmos aplicados, y cómo puedes mejorar el rendimiento de tus modelos."
      ],
      "metadata": {
        "id": "2ndB1QjOieXx"
      }
    }
  ]
}